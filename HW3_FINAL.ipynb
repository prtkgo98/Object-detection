{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals    #All Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy \n",
    "from timeit import default_timer as timer\n",
    "from torch.optim import lr_scheduler\n",
    "%matplotlib inline\n",
    "plt.ion()\n",
    "import xml.etree.ElementTree as xml\n",
    "from pprint import PrettyPrinter\n",
    "import time\n",
    "import cv2\n",
    "from PIL import *\n",
    "import matplotlib.patches as patches\n",
    "from os import path\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import imutils\n",
    "import glob \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the Dataset for Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand_bbox(img):\n",
    "      rsize = 50 + random.randint(0,100)\n",
    "      rxmin = random.randint(0, img.shape[1]-rsize-3)\n",
    "      rxmax = rxmin + rsize\n",
    "      rymin = random.randint(0, img.shape[0]-rsize-3)\n",
    "      rymax = rymin + rsize\n",
    "      bbox = [rxmin, rymin, rxmax, rymax]\n",
    "      return bbox\n",
    "def IoU(box1, box2):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    [x1_min, x1_max, y1_min, y1_max] = box1\n",
    "    [x2_min, x2_max, y2_min, y2_max] = box2\n",
    "    # point A is bottom left corner and point B is top right point of intersection\n",
    "    xA = max(x1_min, x2_min)\n",
    "    xB = min(x1_max, x2_max)\n",
    "    yA = max(y1_min, y2_min)\n",
    "    yB = min(y1_max, y2_max)\n",
    "    if xA > xB or yA > yB:\n",
    "        return 0\n",
    "\n",
    "    intersection = (xB - xA) * (yB - yA)\n",
    "\n",
    "    box1Area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    box2Area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "\n",
    "    iou = intersection / float(box1Area + box2Area - intersection)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Folders for saving images\n",
    "file_path = \"/home/suda/Desktop/val2\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "file_path = \"/home/suda/Desktop/train2\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "file_path = \"/home/suda/Desktop/test2\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "file_path = \"/home/suda/Desktop/val2/bottle\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "file_path = \"/home/suda/Desktop/val2/_background_\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "file_path = \"/home/suda/Desktop/val2/aeroplane\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "file_path = \"/home/suda/Desktop/val2/chair\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "    \n",
    "file_path = \"/home/suda/Desktop/train2/bottle\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "file_path = \"/home/suda/Desktop/train2/_background_\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "file_path = \"/home/suda/Desktop/train2/aeroplane\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "file_path = \"/home/suda/Desktop/train2/chair\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "    \n",
    "    \n",
    "file_path = \"/home/suda/Desktop/test2/bottle\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "file_path = \"/home/suda/Desktop/test2/_background_\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "file_path = \"/home/suda/Desktop/test2/aeroplane\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "file_path = \"/home/suda/Desktop/test2/chair\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter2 = 0\n",
    "counter = 0\n",
    "\n",
    "\n",
    "flag = 1\n",
    "annot_dir ='/home/suda/Desktop/train/VOC2007/Annotations/'\n",
    "image_dir ='/home/suda/Desktop/train/VOC2007/JPEGImages/'\n",
    "\n",
    "\n",
    "t = glob.iglob(annot_dir+'/*')\n",
    "h=  os.listdir(annot_dir)\n",
    "\n",
    "for annot_file in t:\n",
    "    counter2 += 1\n",
    "    if counter2%500 == 1:\n",
    "        print(counter2)\n",
    "\n",
    "\n",
    "    file = open(annot_file,'r')\n",
    "    parsed = xml.parse(file)\n",
    "    root = parsed.getroot()\n",
    "\n",
    "    for child in root.iter('filename'):\n",
    "        img_file = child.text\n",
    "#         print(img_file)\n",
    "\n",
    "    img = cv2.imread(image_dir + img_file)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    objects = []\n",
    "    labels = []\n",
    "\n",
    "    for object in root.iter('object'):\n",
    "        if object[0].text in classes:\n",
    "            xmin = int(float(object[4][0].text))\n",
    "            ymin = int(float(object[4][1].text))\n",
    "            xmax = int(float(object[4][2].text))\n",
    "            ymax = int(float(object[4][3].text))\n",
    "            bbox = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "            objects.append(bbox)\n",
    "            labels.append(object[0].text)\n",
    "\n",
    "    # find random background from the same image\n",
    "    #  for each 3 objects find 1 object; 0 means NO, 1 means YES\n",
    "    for idx in range(len(objects)):\n",
    "        do_take = np.random.choice([0,1], p=[0.6,0.4])\n",
    "        threshold = 0.2\n",
    "\n",
    "        if do_take == 1:\n",
    "            taken = False\n",
    "            img_contour = [img.shape[1],img.shape[0]] * 2\n",
    "\n",
    "            try_count = 0\n",
    "            while not taken:\n",
    "                try_count += 1\n",
    "                if try_count == 5:\n",
    "                    break\n",
    "                valid = True\n",
    "                rand_bbox = get_rand_bbox(img)\n",
    "                for bbox in objects:\n",
    "                    if IoU(bbox, rand_bbox) > threshold:\n",
    "                        valid = False\n",
    "                        break\n",
    "\n",
    "                if valid == True:\n",
    "                    objects.append(rand_bbox)\n",
    "                    labels.append('_background_')\n",
    "                    taken = True\n",
    "\n",
    "    for idx_, object_ in enumerate(objects):\n",
    "        try:\n",
    "            img_object = img[object_[1]:object_[3],object_[0]:object_[2]]\n",
    "            img_object = cv2.resize(img_object, (224,224))\n",
    "            counter = counter + 1\n",
    "            prefix_train = '/home/suda/Desktop/train2/'\n",
    "            prefix_val = '/home/suda/Desktop/val2/'\n",
    "            if labels[idx_]==\"bottle\" :\n",
    "                if flag % 4 == 1:\n",
    "                    cv2.imwrite(prefix_val+labels[idx_]+'/b'+str(counter)+'.jpg',img_object)\n",
    "                    continue\n",
    "                else:\n",
    "                    cv2.imwrite(prefix_train+labels[idx_]+'/b'+str(counter)+'.jpg',img_object)\n",
    "            flag+=1\n",
    "\n",
    "            if labels[idx_]==\"aeroplane\" :\n",
    "                if flag % 3 == 1:\n",
    "                    cv2.imwrite(prefix_val+labels[idx_]+str(counter)+'.jpg',img_object)\n",
    "                    cv2.imwrite(prefix_val+labels[idx_]+'/a'+str(counter)+'.jpg',img_object)\n",
    "                    cv2.imwrite(prefix_val+labels[idx_]+'/b'+str(counter)+'.jpg',img_object)\n",
    "                    continue\n",
    "                else:\n",
    "                    cv2.imwrite(prefix_train+labels[idx_]+'/b'+str(counter)+'.jpg',img_object)\n",
    "            flag+=1\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the Dataset for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter2 = 0\n",
    "counter = 0\n",
    "\n",
    "flag = 1\n",
    "annot_dir ='/home/suda/Desktop/test/VOC2007/Annotations/'\n",
    "image_dir ='/home/suda/Desktop/test/VOC2007/JPEGImages/'\n",
    "print(\"A\")\n",
    "t = glob.iglob(annot_dir+'/*')\n",
    "h= os.listdir(annot_dir)\n",
    "\n",
    "print(t)\n",
    "type(t)\n",
    "for annot_file in t:\n",
    "\n",
    "    counter2 += 1\n",
    "    if counter2%500 == 1:\n",
    "        print(counter2)\n",
    "\n",
    "    #print(\"B\")\n",
    "\n",
    "    file = open(annot_file,'r')\n",
    "    parsed = xml.parse(file)\n",
    "    root = parsed.getroot()\n",
    "\n",
    "    for child in root.iter('filename'):\n",
    "        img_file = child.text\n",
    "\n",
    "    img = cv2.imread(image_dir + img_file)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    objects = []\n",
    "    labels = []\n",
    "\n",
    "    for object in root.iter('object'):\n",
    "        if object[0].text in classes:\n",
    "            xmin = int(float(object[4][0].text))\n",
    "            ymin = int(float(object[4][1].text))\n",
    "            xmax = int(float(object[4][2].text))\n",
    "            ymax = int(float(object[4][3].text))\n",
    "            bbox = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "            objects.append(bbox)\n",
    "            labels.append(object[0].text)\n",
    "\n",
    "    # find random background from the same image\n",
    "    # for each 3 objects find 1 object; 0 means NO, 1 means YES\n",
    "    for idx in range(len(objects)):\n",
    "        do_take = np.random.choice([0,1], p=[0.6,0.4])\n",
    "        threshold = 0.1\n",
    "\n",
    "        if do_take == 1:\n",
    "            taken = False\n",
    "            img_contour = [img.shape[1],img.shape[0]] * 2\n",
    "\n",
    "            try_count = 0\n",
    "            while not taken:\n",
    "                try_count += 1\n",
    "                if try_count == 5:\n",
    "                    break\n",
    "                valid = True\n",
    "                rand_bbox = get_rand_bbox(img)\n",
    "                for bbox in objects:\n",
    "                    if IoU(bbox, rand_bbox) > threshold:\n",
    "                        valid = False\n",
    "                        break\n",
    "\n",
    "                if valid == True:\n",
    "                    objects.append(rand_bbox)\n",
    "                    labels.append('_background_')\n",
    "                    taken = True\n",
    "    \n",
    "    for idx_, object_ in enumerate(objects):\n",
    "        print(labels[idx_])\n",
    "        try:\n",
    "            img_object = img[object_[1]:object_[3],object_[0]:object_[2]]\n",
    "            img_object = cv2.resize(img_object, (224,224))\n",
    "            counter = counter + 1\n",
    "            prefix_test= '/home/suda/Desktop/test2/'\n",
    "            cv2.imwrite( prefix_test+labels[idx_]+'/'+str(counter)+'.jpg',img_object )\n",
    "\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Training the Model\n",
    "\n",
    "train_on_gpu = cuda.is_available()\n",
    "resnet_input =   224 #size of resnet18 input images\n",
    "\n",
    "classes = ('__background__',\n",
    "           'aeroplane',\n",
    "           'bottle','chair'\n",
    "           )\n",
    "\n",
    "traindir ='/content/drive/My Drive/dataset1/train2/'\n",
    "validdir ='/content/drive/My Drive/dataset1/val2/'\n",
    "testdir = '/content/drive/My Drive/dataset/testset/'\n",
    "\n",
    "save_file_name = 'resnet18-transfer-4.pt'\n",
    "checkpoint_path = 'resnet18-transfer-4.pth'\n",
    "\n",
    "# Change to fit hardware\n",
    "batch_size = 128\n",
    "\n",
    "categories = []\n",
    "img_categories = []\n",
    "n_train = []\n",
    "n_valid = []\n",
    "n_test = []\n",
    "\n",
    "# Iterate through each category\n",
    "for d in os.listdir(traindir):\n",
    "    categories.append(d)\n",
    "\n",
    "    # Number of each image\n",
    "    train_imgs = os.listdir(traindir + d)\n",
    "    valid_imgs = os.listdir(validdir + d)\n",
    "    test_imgs = os.listdir(testdir + d)\n",
    "    n_train.append(len(train_imgs))\n",
    "    n_valid.append(len(valid_imgs))\n",
    "    n_test.append(len(test_imgs))\n",
    "\n",
    "    \n",
    "# Image transformations\n",
    "image_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    # Test does not use augmentation\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = {\n",
    "    'train':\n",
    "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
    "    'val':\n",
    "    datasets.ImageFolder(root=validdir, transform=image_transforms['val']),\n",
    "    'test':\n",
    "    datasets.ImageFolder(root=testdir, transform=image_transforms['test'])\n",
    "}\n",
    "\n",
    "# Dataloader iterators\n",
    "dataloaders = {\n",
    "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(data['val'], batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "trainiter = iter(dataloaders['train'])\n",
    "features, labels = next(trainiter)\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "hyp_momentum = 0.9\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          save_file_name,\n",
    "          max_epochs_stop=3,\n",
    "          n_epochs=20,\n",
    "          print_every=2):\n",
    "    \"\"\"Train a PyTorch Model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): cnn to train\n",
    "        criterion (PyTorch loss): objective to minimize\n",
    "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
    "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
    "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
    "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
    "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
    "        n_epochs (int): maximum number of training epochs\n",
    "        print_every (int): frequency of epochs to print training stats\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn with best weights\n",
    "        history (DataFrame): history of train and validation loss and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Early stopping intialization\n",
    "    epochs_no_improve = 0\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "\n",
    "    # Number of epochs already trained (if using loaded in model weights)\n",
    "    try:\n",
    "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print(f'Starting Training from Scratch.\\n')\n",
    "\n",
    "    overall_start = timer()\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # keep track of training and validation loss each epoch\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "\n",
    "        # Set to training\n",
    "        model.train()\n",
    "        start = timer()\n",
    "\n",
    "        # Training loop\n",
    "        for ii, (data, target) in enumerate(train_loader):\n",
    "            # Tensors to gpu\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Predicted outputs are log probabilities\n",
    "            output = model(data)\n",
    "\n",
    "            # Loss and backpropagation of gradients\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track train loss by multiplying average loss by number of examples in batch\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # Calculate accuracy by finding max log probability\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "            # Need to convert correct tensor from int to float to average\n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "            # Multiply average accuracy times the number of examples in batch\n",
    "            train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "            # Track training progress\n",
    "            print(\n",
    "                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
    "                end='\\r')\n",
    "\n",
    "        # After training loops ends, start validation\n",
    "        else:\n",
    "            model.epochs += 1\n",
    "\n",
    "            # Don't need to keep track of gradients\n",
    "            with torch.no_grad():\n",
    "                # Set to evaluation mode\n",
    "                model.eval()\n",
    "\n",
    "                # Validation loop\n",
    "                for data, target in valid_loader:\n",
    "                    # Tensors to gpu\n",
    "                    if train_on_gpu:\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                    # Forward pass\n",
    "                    output = model(data)\n",
    "\n",
    "                    # Validation loss\n",
    "                    loss = criterion(output, target)\n",
    "                    # Multiply average loss times the number of examples in batch\n",
    "                    valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                    # Calculate validation accuracy\n",
    "                    _, pred = torch.max(output, dim=1)\n",
    "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                    accuracy = torch.mean(\n",
    "                        correct_tensor.type(torch.FloatTensor))\n",
    "                    # Multiply average accuracy times the number of examples\n",
    "                    valid_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Calculate average losses\n",
    "                train_loss = train_loss / len(train_loader.dataset)\n",
    "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "                # Calculate average accuracy\n",
    "                train_acc = train_acc / len(train_loader.dataset)\n",
    "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "\n",
    "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "                # Print training and validation results\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\n",
    "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
    "                    )\n",
    "                    print(\n",
    "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
    "                    )\n",
    "\n",
    "                # Save the model if validation loss decreases\n",
    "                if valid_loss < valid_loss_min:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), save_file_name)\n",
    "                    # Track improvement\n",
    "                    epochs_no_improve = 0\n",
    "                    valid_loss_min = valid_loss\n",
    "                    valid_best_acc = valid_acc\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                # Otherwise increment count of epochs with no improvement\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    # Trigger early stopping\n",
    "                    if epochs_no_improve >= max_epochs_stop:\n",
    "                        print(\n",
    "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "                        )\n",
    "                        total_time = timer() - overall_start\n",
    "                        print(\n",
    "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "                        )\n",
    "\n",
    "                        # Load the best state dict\n",
    "                        model.load_state_dict(torch.load(save_file_name))\n",
    "                        # Attach the optimizer\n",
    "                        model.optimizer = optimizer\n",
    "\n",
    "                        # Format history\n",
    "                        history = pd.DataFrame(\n",
    "                            history,\n",
    "                            columns=[\n",
    "                                'train_loss', 'valid_loss', 'train_acc',\n",
    "                                'valid_acc'\n",
    "                            ])\n",
    "                        return model, history\n",
    "\n",
    "    # Attach the optimizer\n",
    "    model.optimizer = optimizer\n",
    "    # Record overall time and print out stats\n",
    "    total_time = timer() - overall_start\n",
    "    print(\n",
    "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "    )\n",
    "    print(\n",
    "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
    "    )\n",
    "    # Format history\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.resnet18(pretrained=True)          #Making of first Model\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Update if any errors occur\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate, hyp_momentum)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model2(nn.Module):               #Making of second Model\n",
    "    def __init__(self,model):\n",
    "        super(model2, self).__init__()\n",
    "        self.features = nn.Sequential(*list(model.children())[:-3])\n",
    "        self.fc = nn.Linear(in_features=50176,out_features=4)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x=self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "model2= model2(resnet18)\n",
    "device = \"cpu\"\n",
    "model2 = model2.to(device)\n",
    "\n",
    "\n",
    "#model2.class_to_idx = data['train'].class_to_idx\n",
    "model2.idx_to_class = {\n",
    "    idx: class_\n",
    "    for class_, idx in model.class_to_idx.items()\n",
    "}\n",
    "model2.idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if train_on_gpu:\n",
    "    model = model.to('cuda')\n",
    "    model2 = model2.to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train(                       #Train First Model\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dataloaders['train'],\n",
    "    dataloaders['val'],\n",
    "    save_file_name=save_file_name,\n",
    "    max_epochs_stop=5,\n",
    "    n_epochs=30,\n",
    "    print_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2, history = train(                  #Train Second Model\n",
    "    model2,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dataloaders['train'],\n",
    "    dataloaders['val'],\n",
    "    save_file_name=save_file_name,\n",
    "    max_epochs_stop=5,\n",
    "    n_epochs=30,\n",
    "    print_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('RES18Final.pt',map_location='cpu')      #First Model\n",
    "model2 = torch.load('Model3.pt',map_location='cpu')      #Second Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_kar(image, model, topk=4):\n",
    "    \n",
    "    img = Image.fromarray(image)\n",
    "    # Resize\n",
    "    img = img.resize((224, 224))\n",
    "\n",
    "    # Convert to numpy, transpose color dimension and normalize\n",
    "    img = np.array(img).transpose((2, 0, 1)) / 256\n",
    "\n",
    "    # Standardization\n",
    "    means = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "    stds = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
    "\n",
    "    img = img - means\n",
    "    img = img / stds\n",
    "    \n",
    "    # Convert to pytorch tensor\n",
    "    img_tensor = torch.Tensor(img)\n",
    "    \n",
    "    # Resize\n",
    "    if False:\n",
    "        img_tensor = img_tensor.view(1, 3, 224, 224).cuda()\n",
    "    else:\n",
    "        img_tensor = img_tensor.view(1, 3, 224, 224)\n",
    "\n",
    "    # Set to evaluation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Model outputs log probabilities\n",
    "        out = model(img_tensor)\n",
    "        ps = torch.exp(out)\n",
    "        #ps=out\n",
    "\n",
    "        # Find the topk predictions\n",
    "        topk, topclass = ps.topk(topk, dim=1)\n",
    "\n",
    "        # Extract the actual classes and probabilities\n",
    "        top_classes = [\n",
    "            model.idx_to_class[class_] for class_ in topclass.cpu().numpy()[0]\n",
    "        ]\n",
    "        top_p = topk.cpu().numpy()[0]\n",
    "\n",
    "        return img_tensor.cpu().squeeze(), top_p, top_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#window_sizes =[(224,224),(112,112),(112,200),(200,112),(64,64),(96,96),(192,96),(96,192),(64,128),(128,64)]\n",
    "#window_sizes=[(300,250),(400,250),(200,100),(250,400),(100,200),(150,150),(250,300),(300,300),(100,100)]\n",
    "window_sizes =[(128,128),(64,64),(64,128),(128,64)]\n",
    "#window_sizes=[(256,128)]\n",
    "#window_sizes =[(100,200),(100,100),(200,200),(200,100)]\n",
    "\n",
    "\n",
    "\n",
    "def pyramid(image, scale=1.5, minSize=(30, 30)):\n",
    "    yield image\n",
    "    while True:\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = imutils.resize(image, width=w)\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break   \n",
    "        yield image\n",
    "\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    for y in range(0, image.shape[1], stepSize):\n",
    "        for x in range(0, image.shape[0], stepSize):\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def slid_win(path,step):\n",
    "    bboxes = []\n",
    "    image =  cv2.imread(path)\n",
    "    for (winW,winH) in window_sizes:\n",
    "        for resized in pyramid(image, scale=2):\n",
    "            for (x, y, window) in sliding_window(resized, stepSize=step, windowSize=(winW, winH)):\n",
    "                if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                window=image[x:x+winW,y:y+winH]\n",
    "                window=cv2.cvtColor(window,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                window=cv2.resize(window,(224,224))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                img, top_p, top_classes = predict_kar(window,model,4)\n",
    "                top_p=top_p/np.sum(top_p)\n",
    "                score = top_p[0]\n",
    "                preds = top_classes[0]\n",
    "\n",
    "                if preds!=\"__background__\":\n",
    "                    if score > 0.9:\n",
    "                        bboxes.append({\"class\":preds,'bbox':[x,y,x+winW,y+winH],'score':score})\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slid_win_2d(path,step):\n",
    "    bboxes = []\n",
    "    image =  cv2.imread(path)\n",
    "    for (winW,winH) in window_sizes:\n",
    "        for resized in pyramid(image, scale=2):\n",
    "            for (x, y, window) in sliding_window(resized, stepSize=step, windowSize=(winW, winH)):\n",
    "                if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                window=image[x:x+winW,y:y+winH]\n",
    "                window=cv2.cvtColor(window,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                window=cv2.resize(window,(224,224))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                img, top_p, top_classes = predict_kar(window,model,4)\n",
    "                top_p=top_p/np.sum(top_p)\n",
    "                score = top_p[0]\n",
    "                preds = top_classes[0]\n",
    "                \n",
    "                img2, top_p2, top_classes2 = predict_kar(window,model2,4)\n",
    "                top_p2=top_p2/np.sum(top_p2)\n",
    "                score2 = top_p2[0]\n",
    "                preds2 = top_classes2[0]\n",
    "                                \n",
    "\n",
    "                if preds!='_background_':\n",
    "                    if score > 0.9:\n",
    "                        bboxes.append({\"class\":preds,'bbox':[x,y,x+winW,y+winH],'score':score})\n",
    "                        \n",
    "                if preds2!='_background_':\n",
    "                    if score > 0.9:\n",
    "                        bboxes.append({\"class\":preds2,'bbox':[x,y,x+winW,y+winH],'score':score2})\n",
    "                        \n",
    "                        \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def non_max_suppression_slow(boxes, overlapThresh):\n",
    "\t# if there are no boxes, return an empty list\n",
    "\tif len(boxes) == 0:\n",
    "\t\treturn []\n",
    "\n",
    "\t# initialize the list of picked indexes\n",
    "\tpick = []\n",
    "\n",
    "\t# grab the coordinates of the bounding boxes\n",
    "\tx1 = boxes[:,0]\n",
    "\ty1 = boxes[:,1]\n",
    "\tx2 = boxes[:,2]\n",
    "\ty2 = boxes[:,3]\n",
    "\tscore = boxes[:,4]\n",
    "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\tidxs = np.argsort(score)\n",
    "\n",
    "\t# keep looping while some indexes still remain in the indexes\n",
    "\t# list\n",
    "\twhile len(idxs) > 0:\n",
    "\t\t# grab the last index in the indexes list, add the index\n",
    "\t\t# value to the list of picked indexes, then initialize\n",
    "\t\t# the suppression list (i.e. indexes that will be deleted)\n",
    "\t\t# using the last index\n",
    "\t\tlast = len(idxs) - 1\n",
    "\t\ti = idxs[last]\n",
    "\t\tpick.append(i)\n",
    "\t\tsuppress = [last]\n",
    "\n",
    "\t\t# loop over all indexes in the indexes list\n",
    "\t\tfor pos in range(0, last):\n",
    "\t\t\t# grab the current index\n",
    "\t\t\tj = idxs[pos]\n",
    "\n",
    "\t\t\t# find the largest (x, y) coordinates for the start of\n",
    "\t\t\t# the bounding box and the smallest (x, y) coordinates\n",
    "\t\t\t# for the end of the bounding box\n",
    "\t\t\txx1 = max(x1[i], x1[j])\n",
    "\t\t\tyy1 = max(y1[i], y1[j])\n",
    "\t\t\txx2 = min(x2[i], x2[j])\n",
    "\t\t\tyy2 = min(y2[i], y2[j])\n",
    "\n",
    "\t\t\t# compute the width and height of the bounding box\n",
    "\t\t\tw = max(0, xx2 - xx1 + 1)\n",
    "\t\t\th = max(0, yy2 - yy1 + 1)\n",
    "\n",
    "\t\t\t# compute the ratio of overlap between the computed\n",
    "\t\t\t# bounding box and the bounding box in the area list\n",
    "\t\t\toverlap = float(w * h) / area[j]\n",
    "\n",
    "\t\t\t# if there is sufficient overlap, suppress the\n",
    "\t\t\t# current bounding box\n",
    "\t\t\tif overlap > overlapThresh:\n",
    "\t\t\t\tsuppress.append(pos)\n",
    "\n",
    "\t\t# delete all indexes from the index list that are in the\n",
    "\t\t# suppression list\n",
    "\t\tidxs = np.delete(idxs, suppress)\n",
    "\n",
    "\t# return only the bounding boxes that were picked\n",
    "\treturn boxes[pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer():\n",
    "    count = 0                   #Making of boxes[]\n",
    "    boxes = []\n",
    "    for i in test_imgs:\n",
    "      path = voc_dir+i\n",
    "      l = slid_win(path,40)\n",
    "      boxes.append({\"name\": path, \" boundary \": l })\n",
    "      print(count)\n",
    "      print(boxes[count])\n",
    "      count = count + 1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    cnt=0                                      #Showing all the boxes\n",
    "    for i in test_imgs:\n",
    "        path = voc_dir+i\n",
    "\n",
    "        img=cv2.imread(path)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        for x in boxes[cnt][\" boundary \"]:\n",
    "            plt.gca().add_patch(patches.Rectangle((x['bbox'][0],x['bbox'][1]),x['bbox'][2] - x['bbox'][0],x['bbox'][3] - x['bbox'][1],linewidth=1,edgecolor='r',facecolor='none'))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        cnt=cnt+1\n",
    "\n",
    "    n_images1= []                   #Making of n_images\n",
    "    n_images2= []\n",
    "    n_images3= []\n",
    "\n",
    "    for i in range(0,len(boxes)):\n",
    "        length = len(boxes[i][\" boundary \"])\n",
    "        if(length == 0):\n",
    "            continue\n",
    "\n",
    "        arr1 = np.zeros((length,6))\n",
    "        arr2 = np.zeros((length,6))\n",
    "        arr3 = np.zeros((length,6))\n",
    "        k1=0\n",
    "        k2=0\n",
    "        k3=0\n",
    "\n",
    "        for x in boxes[i][\" boundary \"]:\n",
    "            if x['class']==\"aeroplane\":\n",
    "                for j in range(0,4):\n",
    "                    arr1[k1][j] = x['bbox'][j]\n",
    "                arr1[k1][4]=x['score']\n",
    "                arr1[k1][5]=1\n",
    "                k1 = k1+1\n",
    "            if x['class']==\"bottle\":\n",
    "                for j in range(0,4):\n",
    "                    arr2[k2][j] =x['bbox'][j]\n",
    "                arr2[k2][4] = x['score']\n",
    "                arr2[k2][5]=2\n",
    "                k2 = k2+1\n",
    "            if x['class']==\"chair\":\n",
    "                for j in range(0,4):\n",
    "                    arr3[k3][j]=x['bbox'][j]\n",
    "                arr3[k3][4]= x['score']\n",
    "                arr3[k3][5]=3\n",
    "                k3 = k3+1  \n",
    "\n",
    "        if(k1 != 0):\n",
    "            while(k1<length):\n",
    "                arr1 = np.delete(arr1, -1 , 0)\n",
    "                k1 = k1+1\n",
    "            n_images1.append(( boxes[i]['name'], arr1 )) \n",
    "\n",
    "        if k2 != 0 :  \n",
    "            while(k2<length):\n",
    "                k2= k2+1\n",
    "                arr2 = np.delete(arr2, -1  , 0)\n",
    "            n_images2.append((boxes[i]['name'] , arr2 ))\n",
    "\n",
    "        if k3 != 0:\n",
    "            while(k3 < length ):\n",
    "                arr3 = np.delete(arr3 , -1 , 0)\n",
    "                k3 = k3 +1\n",
    "            n_images3.append(( boxes[i]['name'], arr3 ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    d = defaultdict(list)                     #showing boxes after applying NMS\n",
    "    # construct a list containing the images that will be examined\n",
    "    # along with their respective bounding boxes\n",
    "    n_images=[n_images1,n_images2,n_images3]\n",
    "    cnt=0\n",
    "    for images in n_images:\n",
    "        cnt=cnt+1\n",
    "\n",
    "        # loop over the images\n",
    "        for (imagePath, boundingBoxes) in images:\n",
    "           \n",
    "            # perform non-maximum suppression on the bounding boxes\n",
    "            pick = non_max_suppression_slow(boundingBoxes, 0.2)\n",
    "            \n",
    "            d[imagePath].append(pick)\n",
    "            cv2.waitKey(0)\n",
    "    cnt=0\n",
    "    h=200\n",
    "    for key, value in d.items():\n",
    "        h=h+1\n",
    "        image = cv2.imread(key)\n",
    "        for pick in value:\n",
    "\n",
    "            for (startX, startY, endX, endY,score,class_name) in pick:\n",
    "                cv2.rectangle(image, (int(startX), int(startY)), (int(endX), int(endY)), (0, 0, 255), 2)\n",
    "        plt.imshow(image)\n",
    "        vocdir1 ='/home/suda/Desktop/'\n",
    "        vocdir1+=str(h)+'.jpg'\n",
    "        plt.savefig(vocdir1)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer():\n",
    "    count = 0                   #Making of boxes[]\n",
    "    boxes = []\n",
    "    for i in test_imgs:\n",
    "      path = voc_dir+i\n",
    "      l = slid_win_2d(path,60)\n",
    "      boxes.append({\"name\": path, \" boundary \": l })\n",
    "      print(count)\n",
    "      print(boxes[count])\n",
    "      count = count + 1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    cnt=0                                      #Showing all the boxes\n",
    "    for i in test_imgs:\n",
    "        path = voc_dir+i\n",
    "\n",
    "        img=cv2.imread(path)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        for x in boxes[cnt][\" boundary \"]:\n",
    "            plt.gca().add_patch(patches.Rectangle((x['bbox'][0],x['bbox'][1]),x['bbox'][2] - x['bbox'][0],x['bbox'][3] - x['bbox'][1],linewidth=1,edgecolor='r',facecolor='none'))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        cnt=cnt+1\n",
    "\n",
    "\n",
    "\n",
    "    n_images1= []                    #Making of n_images\n",
    "    n_images2= []\n",
    "    n_images3= []\n",
    "\n",
    "    for i in range(0,len(boxes)):\n",
    "        length = len(boxes[i][\" boundary \"])\n",
    "        if(length == 0):\n",
    "            continue\n",
    "\n",
    "        arr1 = np.zeros((length,6))\n",
    "        arr2 = np.zeros((length,6))\n",
    "        arr3 = np.zeros((length,6))\n",
    "        k1=0\n",
    "        k2=0\n",
    "        k3=0\n",
    "\n",
    "        for x in boxes[i][\" boundary \"]:\n",
    "            if x['class']==\"aeroplane\":\n",
    "                for j in range(0,4):\n",
    "                    arr1[k1][j] = x['bbox'][j]\n",
    "                arr1[k1][4]=x['score']\n",
    "                arr1[k1][5]=1\n",
    "                k1 = k1+1\n",
    "            if x['class']==\"bottle\":\n",
    "                for j in range(0,4):\n",
    "                    arr2[k2][j] =x['bbox'][j]\n",
    "                arr2[k2][4] = x['score']\n",
    "                arr2[k2][5]=2\n",
    "                k2 = k2+1\n",
    "            if x['class']==\"chair\":\n",
    "                for j in range(0,4):\n",
    "                    arr3[k3][j]=x['bbox'][j]\n",
    "                arr3[k3][4]= x['score']\n",
    "                arr3[k3][5]=3\n",
    "                k3 = k3+1  \n",
    "\n",
    "        if(k1 != 0):\n",
    "            while(k1<length):\n",
    "                arr1 = np.delete(arr1, -1 , 0)\n",
    "                k1 = k1+1\n",
    "            n_images1.append(( boxes[i]['name'], arr1 )) \n",
    "\n",
    "        if k2 != 0 :  \n",
    "            while(k2<length):\n",
    "                k2= k2+1\n",
    "                arr2 = np.delete(arr2, -1  , 0)\n",
    "            n_images2.append((boxes[i]['name'] , arr2 ))\n",
    "\n",
    "        if k3 != 0:\n",
    "            while(k3 < length ):\n",
    "                arr3 = np.delete(arr3 , -1 , 0)\n",
    "                k3 = k3 +1\n",
    "            n_images3.append(( boxes[i]['name'], arr3 ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    d = defaultdict(list)                     #showing boxes after applying NMS\n",
    "    # construct a list containing the images that will be examined\n",
    "    # along with their respective bounding boxes\n",
    "    n_images=[n_images1,n_images2,n_images3]\n",
    "    cnt=0\n",
    "    for images in n_images:\n",
    "        cnt=cnt+1\n",
    "\n",
    "        # loop over the images\n",
    "        for (imagePath, boundingBoxes) in images:\n",
    "            # load the image and clone it\n",
    "            image = cv2.imread(imagePath)\n",
    "            orig = image.copy()\n",
    "\n",
    "           \n",
    "            # perform non-maximum suppression on the bounding boxes\n",
    "            pick = non_max_suppression_slow(boundingBoxes, 0.1)\n",
    "           \n",
    "            d[imagePath].append(pick)\n",
    "            cv2.waitKey(0)\n",
    "    h=0\n",
    "    for key, value in d.items():\n",
    "        h=h+1\n",
    "        image = cv2.imread(key)\n",
    "        orig = image.copy()\n",
    "        for pick in value:\n",
    "            for (startX, startY, endX, endY,score,class_name) in pick:\n",
    "                cv2.rectangle(image, (int(startX), int(startY)), (int(endX), int(endY)), (0, 0, 255), 2)\n",
    "        plt.imshow(image)\n",
    "        vocdir1 ='/home/suda/Desktop/'\n",
    "        vocdir1+=str(5)+'.jpg'\n",
    "        plt.savefig(vocdir1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_dir ='/home/suda/Desktop/JPG/'\n",
    "test_imgs =  os.listdir(voc_dir)\n",
    "len(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "two_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_mAP = 0.5\n",
    "def find_jaccard_overlap(set_1, set_2):\n",
    "    \"\"\"\n",
    "    Find the Jaccard Overlap (IoU) of every box combination between two sets of boxes that are in boundary coordinates.\n",
    "\n",
    "    :param set_1: set 1, a tensor of dimensions (n1, 4)\n",
    "    :param set_2: set 2, a tensor of dimensions (n2, 4)\n",
    "    :return: Jaccard Overlap of each of the boxes in set 1 with respect to each of the boxes in set 2, a tensor of dimensions (n1, n2)\n",
    "    \"\"\"\n",
    "\n",
    "    # Find intersections\n",
    "    intersection = find_intersection(set_1, set_2)  # (n1, n2)\n",
    "\n",
    "    # Find areas of each box in both sets\n",
    "    areas_set_1 = (set_1[:, 2] - set_1[:, 0]) * (set_1[:, 3] - set_1[:, 1])  # (n1)\n",
    "    areas_set_2 = (set_2[:, 2] - set_2[:, 0]) * (set_2[:, 3] - set_2[:, 1])  # (n2)\n",
    "\n",
    "    # Find the union\n",
    "    # PyTorch auto-broadcasts singleton dimensions\n",
    "    union = areas_set_1.unsqueeze(1) + areas_set_2.unsqueeze(0) - intersection  # (n1, n2)\n",
    "\n",
    "    return intersection / union  # (n1, n2)\n",
    "\n",
    "def find_intersection(set_1, set_2):\n",
    "    \"\"\"\n",
    "    Find the intersection of every box combination between two sets of boxes that are in boundary coordinates.\n",
    "\n",
    "    :param set_1: set 1, a tensor of dimensions (n1, 4)\n",
    "    :param set_2: set 2, a tensor of dimensions (n2, 4)\n",
    "    :return: intersection of each of the boxes in set 1 with respect to each of the boxes in set 2, a tensor of dimensions (n1, n2)\n",
    "    \"\"\"\n",
    "\n",
    "    # PyTorch auto-broadcasts singleton dimensions\n",
    "    lower_bounds = torch.max(set_1[:, :2].unsqueeze(1), set_2[:, :2].unsqueeze(0))  # (n1, n2, 2)\n",
    "    upper_bounds = torch.min(set_1[:, 2:].unsqueeze(1), set_2[:, 2:].unsqueeze(0))  # (n1, n2, 2)\n",
    "    intersection_dims = torch.clamp(upper_bounds - lower_bounds, min=0)  # (n1, n2, 2)\n",
    "    return intersection_dims[:, :, 0] * intersection_dims[:, :, 1]  # (n1, n2)\n",
    "def calculate_mAP(det_boxes, det_labels, det_scores, true_boxes, true_labels, true_difficulties):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Average Precision (mAP) of detected objects.\n",
    "\n",
    "    See https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173 for an explanation\n",
    "\n",
    "    :param det_boxes: list of tensors, one tensor for each image containing detected objects' bounding boxes\n",
    "    :param det_labels: list of tensors, one tensor for each image containing detected objects' labels\n",
    "    :param det_scores: list of tensors, one tensor for each image containing detected objects' labels' scores\n",
    "    :param true_boxes: list of tensors, one tensor for each image containing actual objects' bounding boxes\n",
    "    :param true_labels: list of tensors, one tensor for each image containing actual objects' labels\n",
    "    :param true_difficulties: list of tensors, one tensor for each image containing actual objects' difficulty (0 or 1)\n",
    "    :return: list of average precisions for all classes, mean average precision (mAP)\n",
    "    \"\"\"\n",
    "    assert len(det_boxes) == len(det_labels) == len(det_scores) == len(true_boxes) == len(\n",
    "        true_labels) == len(\n",
    "        true_difficulties)  # these are all lists of tensors of the same length, i.e. number of images\n",
    "    #n_classes = len(label_map)\n",
    "    n_classes=4\n",
    "\n",
    "    # Store all (true) objects in a single continuous tensor while keeping track of the image it is from\n",
    "    true_images = list()\n",
    "    for i in range(len(true_labels)):\n",
    "        true_images.extend([i] * true_labels[i].size(0))\n",
    "    true_images = torch.LongTensor(true_images)  # (n_objects), n_objects is the total no. of objects across all images\n",
    "    true_boxes = torch.cat(true_boxes, dim=0)  # (n_objects, 4)\n",
    "    true_labels = torch.cat(true_labels, dim=0)  # (n_objects)\n",
    "    true_difficulties = torch.cat(true_difficulties, dim=0)  # (n_objects)\n",
    "    #print(true_labels.size(0))\n",
    "    assert true_images.size(0) == true_boxes.size(0) == true_labels.size(0)\n",
    "\n",
    "    # Store all detections in a single continuous tensor while keeping track of the image it is from\n",
    "    det_images = list()\n",
    "    for i in range(len(det_labels)):\n",
    "        det_images.extend([i] * det_labels[i].size(0))\n",
    "    det_images = torch.LongTensor(det_images)  # (n_detections)\n",
    "    det_boxes = torch.cat(det_boxes, dim=0)  # (n_detections, 4)\n",
    "    det_labels = torch.cat(det_labels, dim=0)  # (n_detections)\n",
    "    det_scores = torch.cat(det_scores, dim=0)  # (n_detections)\n",
    "\n",
    "    assert det_images.size(0) == det_boxes.size(0) == det_labels.size(0) == det_scores.size(0)\n",
    "\n",
    "    # Calculate APs for each class (except background)\n",
    "    average_precisions = torch.zeros((n_classes - 1), dtype=torch.float)  # (n_classes - 1)\n",
    "    for c in range(1, n_classes):\n",
    "        # Extract only objects with this class\n",
    "        true_class_images = true_images[true_labels == c]  # (n_class_objects)\n",
    "        true_class_boxes = true_boxes[true_labels == c]  # (n_class_objects, 4)\n",
    "        true_class_difficulties = true_difficulties[true_labels == c]  # (n_class_objects)\n",
    "        n_easy_class_objects = (1 - true_class_difficulties).sum().item()  # ignore difficult objects\n",
    "\n",
    "        # Keep track of which true objects with this class have already been 'detected'\n",
    "        # So far, none\n",
    "        true_class_boxes_detected = torch.zeros((true_class_difficulties.size(0)), dtype=torch.uint8)\n",
    "             # (n_class_objects)\n",
    "\n",
    "        # Extract only detections with this class\n",
    "        det_class_images = det_images[det_labels == c]  # (n_class_detections)\n",
    "        det_class_boxes = det_boxes[det_labels == c]  # (n_class_detections, 4)\n",
    "        det_class_scores = det_scores[det_labels == c]  # (n_class_detections)\n",
    "        n_class_detections = det_class_boxes.size(0)\n",
    "        if n_class_detections == 0:\n",
    "            continue\n",
    "\n",
    "        # Sort detections in decreasing order of confidence/scores\n",
    "        det_class_scores, sort_ind = torch.sort(det_class_scores, dim=0, descending=True)  # (n_class_detections)\n",
    "        det_class_images = det_class_images[sort_ind]  # (n_class_detections)\n",
    "        det_class_boxes = det_class_boxes[sort_ind]  # (n_class_detections, 4)\n",
    "\n",
    "        # In the order of decreasing scores, check if true or false positive\n",
    "        true_positives = torch.zeros((n_class_detections), dtype=torch.float)  # (n_class_detections)\n",
    "        false_positives = torch.zeros((n_class_detections), dtype=torch.float)  # (n_class_detections)\n",
    "        for d in range(n_class_detections):\n",
    "            this_detection_box = det_class_boxes[d].unsqueeze(0)  # (1, 4)\n",
    "            this_image = det_class_images[d]  # (), scalar\n",
    "\n",
    "            # Find objects in the same image with this class, their difficulties, and whether they have been detected before\n",
    "            object_boxes = true_class_boxes[true_class_images == this_image]  # (n_class_objects_in_img)\n",
    "            object_difficulties = true_class_difficulties[true_class_images == this_image]  # (n_class_objects_in_img)\n",
    "            # If no such object in this image, then the detection is a false positive\n",
    "            if object_boxes.size(0) == 0:\n",
    "                false_positives[d] = 1\n",
    "                continue\n",
    "\n",
    "            # Find maximum overlap of this detection with objects in this image of this class\n",
    "            overlaps = find_jaccard_overlap(this_detection_box, object_boxes) \n",
    "            #print(overlaps)# (1, n_class_objects_in_img)\n",
    "            max_overlap, ind = torch.max(overlaps.squeeze(0), dim=0)  # (), () - scalars\n",
    "\n",
    "            # 'ind' is the index of the object in these image-level tensors 'object_boxes', 'object_difficulties'\n",
    "            # In the original class-level tensors 'true_class_boxes', etc., 'ind' corresponds to object with index...\n",
    "            original_ind = torch.LongTensor(range(true_class_boxes.size(0)))[true_class_images == this_image][ind]\n",
    "            # We need 'original_ind' to update 'true_class_boxes_detected'\n",
    "\n",
    "            # If the maximum overlap is greater than the threshold of 0.5, it's a match\n",
    "            if max_overlap.item() > thres_mAP:\n",
    "                # If the object it matched with is 'difficult', ignore it\n",
    "                if object_difficulties[ind] == 0:\n",
    "                    # If this object has already not been detected, it's a true positive\n",
    "                    if true_class_boxes_detected[original_ind] == 0:\n",
    "                        true_positives[d] = 1\n",
    "                        true_class_boxes_detected[original_ind] = 1  # this object has now been detected/accounted for\n",
    "                    # Otherwise, it's a false positive (since this object is already accounted for)\n",
    "                    else:\n",
    "                        false_positives[d] = 1\n",
    "            # Otherwise, the detection occurs in a different location than the actual object, and is a false positive\n",
    "            else:\n",
    "                false_positives[d] = 1\n",
    "\n",
    "        # Compute cumulative precision and recall at each detection in the order of decreasing scores\n",
    "        cumul_true_positives = torch.cumsum(true_positives, dim=0)  # (n_class_detections)\n",
    "        cumul_false_positives = torch.cumsum(false_positives, dim=0)  # (n_class_detections)\n",
    "        cumul_precision = cumul_true_positives / (\n",
    "                cumul_true_positives + cumul_false_positives + 1e-10)  # (n_class_detections)\n",
    "        cumul_recall = cumul_true_positives / n_easy_class_objects  # (n_class_detections)\n",
    "\n",
    "        # Find the mean of the maximum of the precisions corresponding to recalls above the threshold 't'\n",
    "        recall_thresholds = torch.arange(start=0, end=1.1, step=.1).tolist()  # (11)\n",
    "        precisions = torch.zeros((len(recall_thresholds)), dtype=torch.float)  # (11)\n",
    "        for i, t in enumerate(recall_thresholds):\n",
    "            recalls_above_t = cumul_recall >= t\n",
    "            if recalls_above_t.any():\n",
    "                precisions[i] = cumul_precision[recalls_above_t].max()\n",
    "            else:\n",
    "                precisions[i] = 0.\n",
    "        average_precisions[c - 1] = precisions.mean()  # c is in [1, n_classes - 1]\n",
    "\n",
    "    # Calculate Mean Average Precision (mAP)\n",
    "    mean_average_precision = average_precisions.mean().item()\n",
    "\n",
    "    # Keep class-wise average precisions in a dictionary\n",
    "    average_precisions = {rev_label_map[c + 1]: v for c, v in enumerate(average_precisions.tolist())}\n",
    "\n",
    "    return average_precisions, mean_average_precision\n",
    "\n",
    "voc_labels = ('aeroplane', 'bottle','chair')\n",
    "label_map = {k: v + 1 for v, k in enumerate(voc_labels)}\n",
    "label_map['background'] = 0\n",
    "rev_label_map = {v: k for k, v in label_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer_mAp():\n",
    "\n",
    "    boxes = []\n",
    "    \n",
    "    true_boxes=[]\n",
    "    true_labels=[]\n",
    "    true_diffi=[]\n",
    "        \n",
    "    det_boxes=[]\n",
    "    det_labels=[]\n",
    "    det_scores=[]\n",
    "\n",
    "    i=0\n",
    "    counter = 0\n",
    "    #annot_dir ='/home/suda/Desktop/test/VOC2007/Annotations/'\n",
    "    image_dir ='/home/suda/Desktop/test/VOC2007/JPEGImages/'\n",
    "    annot_dir ='/home/suda/Desktop/test/VOC2007/Annot/'\n",
    "#     annot_dir ='/home/anurag/academics/Sem 6/CS783/hw3/Anot/'\n",
    "    \n",
    "\n",
    "    t = glob.iglob(annot_dir+'/*')\n",
    "    for annot_file in t:\n",
    "      \n",
    "        i = i+1\n",
    "        print(\"Working on \"+str(i))\n",
    "            \n",
    "        true_boxes_image=[]\n",
    "        true_labels_image=[]\n",
    "        true_diffi_image=[]\n",
    "\n",
    "\n",
    "      \n",
    "        file = open(annot_file,'r')\n",
    "        parsed = xml.parse(file)\n",
    "        root = parsed.getroot()\n",
    "      \n",
    "        for child in root.iter('filename'):\n",
    "            img_file = child.text\n",
    "             \n",
    "        path = image_dir + img_file\n",
    "#         print(path)\n",
    "#         img = cv2.imread(image_dir + img_file)\n",
    "#         img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "      \n",
    "#         objects = []\n",
    "#         labels = []\n",
    "      \n",
    "        for object in root.iter('object'):\n",
    "#             print(object[0].text)\n",
    "            if object[0].text in classes:\n",
    "                xmin = int(float(object[4][0].text))\n",
    "                ymin = int(float(object[4][1].text))\n",
    "                xmax = int(float(object[4][2].text))\n",
    "                ymax = int(float(object[4][3].text))\n",
    "                \n",
    "                \n",
    "                true_boxes_image.append(torch.Tensor([xmin,ymin,xmax,ymax]))\n",
    "                true_labels_image.append(model.class_to_idx[object[0].text]) ######### check~~~\n",
    "#                 print(object[0].text)\n",
    "#                 print(model.class_to_idx[object[0].text])\n",
    "                true_diffi_image.append(0)\n",
    "                \n",
    "                \n",
    "        if(len(true_boxes_image)==0):\n",
    "            print('  No objects in test image#'+np.str(i))\n",
    "            continue\n",
    "        else:\n",
    "            true_boxes_image=torch.stack(true_boxes_image)\n",
    "            true_diffi_image=torch.Tensor(true_diffi_image)\n",
    "            true_labels_image=torch.Tensor(true_labels_image) \n",
    "            \n",
    "#             print(true_boxes_image)\n",
    "#             print(true_diffi_image)\n",
    "#             print(true_labels_image)\n",
    "\n",
    "            true_boxes.append(true_boxes_image)\n",
    "            true_diffi.append(true_diffi_image)\n",
    "            true_labels.append(true_labels_image)\n",
    "            \n",
    "#             print(path)\n",
    "            l = slid_win(path,50)\n",
    "            \n",
    "#             print(l)\n",
    "#             boxes.append({\"name\": path, \" boundary \": l })\n",
    "            \n",
    "            \n",
    "            bBox={'aeroplane':[],'bottle':[],'chair':[]}\n",
    "            bBox_mod={'aeroplane':[],'bottle':[],'chair':[]}\n",
    "            \n",
    "            for item in l:\n",
    "                if item['class']=='aeroplane' :\n",
    "                    bBox['aeroplane'].append([item['bbox'][0],item['bbox'][1],item['bbox'][2],item['bbox'][3], item['score']])\n",
    "                if item['class']=='bottle' :\n",
    "                    bBox['bottle'].append([item['bbox'][0],item['bbox'][1],item['bbox'][2],item['bbox'][3], item['score']])          \n",
    "                if item['class']=='chair' :\n",
    "                    bBox['chair'].append([item['bbox'][0],item['bbox'][1],item['bbox'][2],item['bbox'][3], item['score']])\n",
    "    \n",
    "#             print(\"printing bBox NOW\")\n",
    "#             print(bBox)\n",
    "        \n",
    "        \n",
    "            for k in bBox:\n",
    "                bBox[k]=np.asarray(bBox[k])\n",
    "                bBox_mod[k] =  non_max_suppression_slow(bBox[k],0.3)   ######  NMS ###########\n",
    "            \n",
    "#             print()\n",
    "#             print(\"printing AFTER NMS\")\n",
    "#             print(bBox_mod)\n",
    "            det_boxes_image=[]\n",
    "            det_labels_image=[]\n",
    "            det_scores_image=[]\n",
    "\n",
    "            for k in bBox_mod:\n",
    "                for box in bBox_mod[k]:\n",
    "                    det_boxes_image.append(torch.Tensor(box[0:4]))\n",
    "                    det_scores_image.append(box[4])\n",
    "                    det_labels_image.append(model.class_to_idx[k])\n",
    "\n",
    "            flag_for_no_detect=0\n",
    "            for k in bBox_mod:\n",
    "                if(len(bBox_mod[k])!=0):\n",
    "                    flag_for_no_detect=1\n",
    "\n",
    "            if(flag_for_no_detect==0):\n",
    "                print('  No objects  detected in image#'+np.str(i))\n",
    "                true_boxes=true_boxes[:-1]\n",
    "                true_diffi=true_diffi[:-1]\n",
    "                true_labels=true_labels[:-1]\n",
    "                continue\n",
    "\n",
    "            det_boxes_image=torch.stack(det_boxes_image)\n",
    "            det_scores_image=torch.Tensor(det_scores_image)\n",
    "            det_labels_image=torch.Tensor(det_labels_image)\n",
    "\n",
    "            det_boxes.append(det_boxes_image)\n",
    "            det_scores.append(det_scores_image)\n",
    "            det_labels.append(det_labels_image)\n",
    "    # Good formatting when printing the APs for each class and mAP\n",
    "    \n",
    "    pp = PrettyPrinter()\n",
    "\n",
    "\n",
    "    # Calculate mAP\n",
    "    if(len(det_boxes)==0):\n",
    "        print(\"### Nothing detected in all images ####\")\n",
    "    else:\n",
    "        APs, mAP = calculate_mAP(det_boxes, det_labels, det_scores, true_boxes, true_labels\n",
    "                             ,true_diffi) \n",
    "\n",
    "    # Print AP for each class\n",
    "    print(\"done!\")\n",
    "    pp.pprint(APs)\n",
    "\n",
    "    print('\\nMean Average Precision (mAP): %.3f' % mAP)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_layer_mAp():\n",
    "\n",
    "    boxes = []\n",
    "    \n",
    "    true_boxes=[]\n",
    "    true_labels=[]\n",
    "    true_diffi=[]\n",
    "        \n",
    "    det_boxes=[]\n",
    "    det_labels=[]\n",
    "    det_scores=[]\n",
    "\n",
    "    i=0\n",
    "    counter = 0\n",
    "    #annot_dir ='/home/suda/Desktop/test/VOC2007/Annotations/'\n",
    "    image_dir ='/home/suda/Desktop/test/VOC2007/JPEGImages/'\n",
    "    annot_dir ='/home/suda/Desktop/test/VOC2007/Annot/'\n",
    "#     annot_dir ='/home/anurag/academics/Sem 6/CS783/hw3/Anot/'\n",
    "\n",
    "    t = glob.iglob(annot_dir+'/*')\n",
    "    for annot_file in t:\n",
    "      \n",
    "        i = i+1\n",
    "        print(\"Working on \"+str(i))\n",
    "            \n",
    "        true_boxes_image=[]\n",
    "        true_labels_image=[]\n",
    "        true_diffi_image=[]\n",
    "\n",
    "\n",
    "      \n",
    "        file = open(annot_file,'r')\n",
    "        parsed = xml.parse(file)\n",
    "        root = parsed.getroot()\n",
    "      \n",
    "        for child in root.iter('filename'):\n",
    "            img_file = child.text\n",
    "             \n",
    "        path = image_dir + img_file\n",
    "#         print(path)\n",
    "#         img = cv2.imread(image_dir + img_file)\n",
    "#         img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "      \n",
    "#         objects = []\n",
    "#         labels = []\n",
    "      \n",
    "        for object in root.iter('object'):\n",
    "#             print(object[0].text)\n",
    "            if object[0].text in classes:\n",
    "                xmin = int(float(object[4][0].text))\n",
    "                ymin = int(float(object[4][1].text))\n",
    "                xmax = int(float(object[4][2].text))\n",
    "                ymax = int(float(object[4][3].text))\n",
    "                \n",
    "                \n",
    "                true_boxes_image.append(torch.Tensor([xmin,ymin,xmax,ymax]))\n",
    "                true_labels_image.append(model.class_to_idx[object[0].text]) ######### check~~~\n",
    "#                 print(object[0].text)\n",
    "#                 print(model.class_to_idx[object[0].text])\n",
    "                true_diffi_image.append(0)\n",
    "                \n",
    "                \n",
    "        if(len(true_boxes_image)==0):\n",
    "            print('  No objects in test image#'+np.str(i))\n",
    "            continue\n",
    "        else:\n",
    "            true_boxes_image=torch.stack(true_boxes_image)\n",
    "            true_diffi_image=torch.Tensor(true_diffi_image)\n",
    "            true_labels_image=torch.Tensor(true_labels_image) \n",
    "            \n",
    "#             print(true_boxes_image)\n",
    "#             print(true_diffi_image)\n",
    "#             print(true_labels_image)\n",
    "\n",
    "            true_boxes.append(true_boxes_image)\n",
    "            true_diffi.append(true_diffi_image)\n",
    "            true_labels.append(true_labels_image)\n",
    "            \n",
    "#             print(path)\n",
    "            l = slid_win_2d(path,50)\n",
    "            \n",
    "#             print(l)\n",
    "#             boxes.append({\"name\": path, \" boundary \": l })\n",
    "            \n",
    "            \n",
    "            bBox={'aeroplane':[],'bottle':[],'chair':[]}\n",
    "            bBox_mod={'aeroplane':[],'bottle':[],'chair':[]}\n",
    "            \n",
    "            for item in l:\n",
    "                if item['class']=='aeroplane' :\n",
    "                    bBox['aeroplane'].append([item['bbox'][0],item['bbox'][1],item['bbox'][2],item['bbox'][3], item['score']])\n",
    "                if item['class']=='bottle' :\n",
    "                    bBox['bottle'].append([item['bbox'][0],item['bbox'][1],item['bbox'][2],item['bbox'][3], item['score']])          \n",
    "                if item['class']=='chair' :\n",
    "                    bBox['chair'].append([item['bbox'][0],item['bbox'][1],item['bbox'][2],item['bbox'][3], item['score']])\n",
    "    \n",
    "#             print(\"printing bBox NOW\")\n",
    "#             print(bBox)\n",
    "        \n",
    "        \n",
    "            for k in bBox:\n",
    "                bBox[k]=np.asarray(bBox[k])\n",
    "                bBox_mod[k] =  non_max_suppression_slow(bBox[k],0.3)   ######  NMS ###########\n",
    "            \n",
    "#             print()\n",
    "#             print(\"printing AFTER NMS\")\n",
    "#             print(bBox_mod)\n",
    "            det_boxes_image=[]\n",
    "            det_labels_image=[]\n",
    "            det_scores_image=[]\n",
    "\n",
    "            for k in bBox_mod:\n",
    "                for box in bBox_mod[k]:\n",
    "                    det_boxes_image.append(torch.Tensor(box[0:4]))\n",
    "                    det_scores_image.append(box[4])\n",
    "                    det_labels_image.append(model.class_to_idx[k])\n",
    "\n",
    "            flag_for_no_detect=0\n",
    "            for k in bBox_mod:\n",
    "                if(len(bBox_mod[k])!=0):\n",
    "                    flag_for_no_detect=1\n",
    "\n",
    "            if(flag_for_no_detect==0):\n",
    "                print('  No objects  detected in image#'+np.str(i))\n",
    "                true_boxes=true_boxes[:-1]\n",
    "                true_diffi=true_diffi[:-1]\n",
    "                true_labels=true_labels[:-1]\n",
    "                continue\n",
    "\n",
    "            det_boxes_image=torch.stack(det_boxes_image)\n",
    "            det_scores_image=torch.Tensor(det_scores_image)\n",
    "            det_labels_image=torch.Tensor(det_labels_image)\n",
    "\n",
    "            det_boxes.append(det_boxes_image)\n",
    "            det_scores.append(det_scores_image)\n",
    "            det_labels.append(det_labels_image)\n",
    "    # Good formatting when printing the APs for each class and mAP\n",
    "    pp = PrettyPrinter()\n",
    "\n",
    "\n",
    "    # Calculate mAP\n",
    "    if(len(det_boxes)==0):\n",
    "        print(\"### Nothing detected in all images ####\")\n",
    "    else:\n",
    "        APs, mAP = calculate_mAP(det_boxes, det_labels, det_scores, true_boxes, true_labels\n",
    "                             ,true_diffi) \n",
    "\n",
    "    # Print AP for each class\n",
    "    print(\"done!\")\n",
    "    pp.pprint(APs)\n",
    "\n",
    "    print('\\nMean Average Precision (mAP): %.3f' % mAP)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_layer_mAp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_layer_mAp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model2, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
